{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RF2uyPfxgi8H"
      },
      "source": [
        "# TO USE: \n",
        "#    1. Upload your recorded tone sample .wav file from the SmartAmpPro plugin.\n",
        "#    2 Upload the \"plot.py\" python script\n",
        "#    3. Select a runtime (GPU recommended)\n",
        "#    4. Change the \"in_file\" variable to match your uploaded file. \n",
        "#    5 Change the \"name\" file to the desired model name\n",
        "#    6. Click \"Runtime\" then \"Run All\"\n",
        "#    7. To run another, reset the runtime to free up RAM\n",
        "#\n",
        "#     Note: Tested on CPU and GPU runtimes.\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Conv1D, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.backend import clear_session\n",
        "from tensorflow.keras.activations import tanh, elu, relu\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.utils import Sequence\n",
        "\n",
        "import os\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import h5py\n",
        "import json\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U22mDBe4jaf2"
      },
      "source": [
        "# EDIT THIS SECTION FOR USER INPUTS\n",
        "#\n",
        "name = 'my_model'\n",
        "in_file = 'SmartAmpProSample.wav'\n",
        "\n",
        "epochs = 3  # Increase epochs to try extended training to improve model results\n",
        "split_data = 6 # **Increase this to reduce RAM usage **\n",
        "learning_rate = 0.01 \n",
        "hidden_units = 24\n",
        "\n",
        "input_size = 120 # Using input_size > 140 will not work in SmartAmpPro\n",
        "\n",
        "if not os.path.exists('models/'+name):\n",
        "    os.makedirs('models/'+name)\n",
        "else:\n",
        "    print(\"A model with the same name already exists. Please choose a new name.\")\n",
        "    exit\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqI-cGt1jaG2"
      },
      "source": [
        "\n",
        "def pre_emphasis_filter(x, coeff=0.95):\n",
        "    return tf.concat([x, x - coeff * x], 1)\n",
        "    \n",
        "def error_to_signal(y_true, y_pred): \n",
        "    \"\"\"\n",
        "    Error to signal ratio with pre-emphasis filter:\n",
        "    \"\"\"\n",
        "    y_true, y_pred = pre_emphasis_filter(y_true), pre_emphasis_filter(y_pred)\n",
        "    return K.sum(tf.pow(y_true - y_pred, 2), axis=0) / K.sum(tf.pow(y_true, 2), axis=0) + 1e-10\n",
        "    \n",
        "def save_wav(name, data):\n",
        "    wavfile.write(name, 44100, data.flatten().astype(np.float32))\n",
        "\n",
        "def normalize(data):\n",
        "    data_max = max(data)\n",
        "    data_min = min(data)\n",
        "    data_norm = max(data_max,abs(data_min))\n",
        "    return data / data_norm\n",
        "\n",
        "\n",
        "'''This is a similar Tensorflow/Keras implementation of the LSTM model from the paper:\n",
        "    \"Real-Time Guitar Amplifier Emulation with Deep Learning\"\n",
        "    https://www.mdpi.com/2076-3417/10/3/766/htm\n",
        "\n",
        "    Uses a stack of two 1-D Convolutional layers, followed by LSTM, followed by \n",
        "    a Dense (fully connected) layer. Three preset training modes are available, \n",
        "    with further customization by editing the code. A Sequential tf.keras model \n",
        "    is implemented here.\n",
        "\n",
        "    Note: RAM may be a limiting factor for the parameter \"input_size\". The wav data\n",
        "      is preprocessed and stored in RAM, which improves training speed but quickly runs out\n",
        "      if using a large number for \"input_size\".  Reduce this if you are experiencing\n",
        "      RAM issues. \n",
        "    \n",
        "    --training_mode=0   Speed training (default)\n",
        "    --training_mode=1   Accuracy training\n",
        "    --training_mode=2   Extended training (set max_epochs as desired, for example 50+)\n",
        "'''\n",
        "\n",
        "batch_size = 4096 \n",
        "test_size = 0.2\n",
        "\n",
        "conv1d_strides = 12\n",
        "conv1d_1_strides = 12   \n",
        "conv1d_filters = 4\n",
        "\n",
        "conv1d_KS = conv1d_strides \n",
        "conv1d_1_KS = conv1d_1_strides\n",
        "\n",
        "# Create Sequential Model ###########################################\n",
        "clear_session()\n",
        "model = Sequential()\n",
        "model.add(Conv1D(conv1d_filters, conv1d_KS, strides=conv1d_strides, activation=None, padding='same',input_shape=(input_size,1)))\n",
        "model.add(Conv1D(conv1d_filters, conv1d_1_KS, strides=conv1d_1_strides, activation=None, padding='same'))\n",
        "model.add(LSTM(hidden_units))\n",
        "model.add(Dense(1, activation=None))\n",
        "model.compile(optimizer=Adam(learning_rate=learning_rate), loss=error_to_signal, metrics=[error_to_signal])\n",
        "print(model.summary())\n",
        "\n",
        "# Load and Preprocess Data ###########################################\n",
        "#in_rate, in_data = wavfile.read(in_file)\n",
        "#out_rate, out_data = wavfile.read(out_file)\n",
        "in_rate, stereo_data = wavfile.read(in_file)\n",
        "\n",
        "in_data = stereo_data.T[0]\n",
        "out_data = stereo_data.T[1]\n",
        "\n",
        "X_all = in_data.astype(np.float32).flatten()  \n",
        "X_all = normalize(X_all).reshape(len(X_all),1)   \n",
        "y_all = out_data.astype(np.float32).flatten() \n",
        "y_all = normalize(y_all).reshape(len(y_all),1)   \n",
        "\n",
        "# If splitting the data for training, do this part\n",
        "if split_data > 1:\n",
        "    num_split = len(X_all) // split_data\n",
        "    X = X_all[0:num_split*split_data]\n",
        "    y = y_all[0:num_split*split_data]\n",
        "    X_data = np.split(X, split_data)\n",
        "    y_data = np.split(y, split_data)\n",
        "\n",
        "    # Perform training on each split dataset\n",
        "    for i in range(len(X_data)):\n",
        "        print(\"\\nTraining on split data \" + str(i+1) + \"/\" +str(len(X_data)))\n",
        "        X_split = X_data[i]\n",
        "        y_split = y_data[i]\n",
        "\n",
        "        y_ordered = y_split[input_size-1:] \n",
        "\n",
        "        indices = np.arange(input_size) + np.arange(len(X_split)-input_size+1)[:,np.newaxis] \n",
        "        X_ordered = tf.gather(X_split,indices) \n",
        "\n",
        "        shuffled_indices = np.random.permutation(len(X_ordered)) \n",
        "        X_random = tf.gather(X_ordered,shuffled_indices)\n",
        "        y_random = tf.gather(y_ordered, shuffled_indices)\n",
        "\n",
        "        # Train Model ###################################################\n",
        "        model.fit(X_random,y_random, epochs=epochs, batch_size=batch_size, validation_split=0.2)  \n",
        "\n",
        "\n",
        "    model.save('models/'+name+'/'+name+'.h5')\n",
        "\n",
        "# If training on the full set of input data in one run, do this part\n",
        "else:\n",
        "    y_ordered = y_all[input_size-1:] \n",
        "\n",
        "    indices = np.arange(input_size) + np.arange(len(X_all)-input_size+1)[:,np.newaxis] \n",
        "    X_ordered = tf.gather(X_all,indices) \n",
        "\n",
        "    shuffled_indices = np.random.permutation(len(X_ordered)) \n",
        "    X_random = tf.gather(X_ordered,shuffled_indices)\n",
        "    y_random = tf.gather(y_ordered, shuffled_indices)\n",
        "\n",
        "    # Train Model ###################################################\n",
        "    model.fit(X_random,y_random, epochs=epochs, batch_size=batch_size, validation_split=test_size)    \n",
        "\n",
        "    model.save('models/'+name+'/'+name+'.h5')\n",
        "\n",
        "# Run Prediction #################################################\n",
        "#print(\"Running prediction..\")\n",
        "\n",
        "# Get the last 20% of the wav data to run prediction and plot results\n",
        "y_the_rest, y_last_part = np.split(y_all, [int(len(y_all)*.8)])\n",
        "x_the_rest, x_last_part = np.split(X_all, [int(len(X_all)*.8)])\n",
        "y_test = y_last_part[input_size-1:] \n",
        "indices = np.arange(input_size) + np.arange(len(x_last_part)-input_size+1)[:,np.newaxis] \n",
        "X_test = tf.gather(x_last_part,indices) \n",
        "\n",
        "prediction = model.predict(X_test, batch_size=batch_size)\n",
        "\n",
        "save_wav('models/'+name+'/y_pred.wav', prediction)\n",
        "save_wav('models/'+name+'/x_test.wav', x_last_part)\n",
        "save_wav('models/'+name+'/y_test.wav', y_test)\n",
        "\n",
        "# Add additional data to the saved model (like input_size)\n",
        "filename = 'models/'+name+'/'+name+'.h5'\n",
        "f = h5py.File(filename, 'a')\n",
        "grp = f.create_group(\"info\")\n",
        "dset = grp.create_dataset(\"input_size\", (1,), dtype='int16')\n",
        "dset[0] = input_size\n",
        "dset2 = grp.create_dataset(\"conv1d_stride\", (1,), dtype='int16')\n",
        "dset3 = grp.create_dataset(\"conv1d_1_stride\", (1,), dtype='int16')\n",
        "dset[0] = input_size\n",
        "dset2[0] = conv1d_strides\n",
        "dset3[0] = conv1d_1_strides\n",
        "\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OV7hybs5eXBS"
      },
      "source": [
        "  # Generate json model ################################\r\n",
        "  filename = 'models/'+name+'/'+ name +'.h5'\r\n",
        "  json_filename = 'models/'+name+'/'+ name\r\n",
        "  f = h5py.File(filename, 'r')\r\n",
        "\r\n",
        "  # Load the model data\r\n",
        "  data = {}\r\n",
        "  for layer in f[\"model_weights\"].keys():\r\n",
        "      if layer not in data.keys():\r\n",
        "          data[layer] = {}\r\n",
        "      for item in f[\"model_weights\"][layer][layer]:\r\n",
        "          if item not in data[layer].keys():\r\n",
        "              data[layer][item] = {}\r\n",
        "              try:\r\n",
        "                  data[layer][item] = f[\"model_weights\"][layer][layer][item][:].tolist()\r\n",
        "              except:\r\n",
        "                  data[layer][\"kernel:0\"] = f[\"model_weights\"][layer][layer][item][\"kernel:0\"][:].tolist()\r\n",
        "                  data[layer][\"bias:0\"] = f[\"model_weights\"][layer][layer][item][\"bias:0\"][:].tolist()\r\n",
        "          else:\r\n",
        "              try:\r\n",
        "                  data[layer][item] = f[\"model_weights\"][layer][layer][item][:].tolist()\r\n",
        "              except:\r\n",
        "                  data[layer][\"kernel:0\"] = f[\"model_weights\"][layer][layer][item][\"kernel:0\"][:].tolist()\r\n",
        "                  data[layer][\"bias:0\"] = f[\"model_weights\"][layer][layer][item][\"bias:0\"][:].tolist()\r\n",
        "\r\n",
        "  input_size = f[\"info\"][\"input_size\"][0]\r\n",
        "  conv1d_strides = f[\"info\"][\"conv1d_stride\"][0]\r\n",
        "  conv1d_1_strides = f[\"info\"][\"conv1d_1_stride\"][0]\r\n",
        "  data['input_size'] = int(input_size)\r\n",
        "  print(\"input_size: \",input_size)\r\n",
        "  data['conv1d_stride'] = int(conv1d_strides)\r\n",
        "  data['conv1d_1_stride'] = int(conv1d_1_strides)\r\n",
        "  f.close()\r\n",
        "\r\n",
        "  with open(json_filename + \".json\", 'w') as outfile:\r\n",
        "      json.dump(data, outfile)\r\n",
        "  print(\"SmartAmpPro model generated: \", json_filename + \".json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJFGh1hDimp-"
      },
      "source": [
        "        print(\"Plotting results..\")\r\n",
        "        import plot\r\n",
        "\r\n",
        "        plot.analyze_pred_vs_actual({   'output_wav':'models/'+name+'/y_test.wav',\r\n",
        "                                            'pred_wav':'models/'+name+'/y_pred.wav', \r\n",
        "                                            'input_wav':'models/'+name+'/x_test.wav',\r\n",
        "                                            'model_name':name,\r\n",
        "                                            'show_plots':1,\r\n",
        "                                            'path':'models/'+name\r\n",
        "                                        })"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}